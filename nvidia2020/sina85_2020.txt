不再靠你买显卡充值信仰，英伟达已经变了
原标题：不再靠你买显卡充值信仰，英伟达已经变了    来源：极客公园
千亿规模的服务器芯片市场，是英伟达的第二增长曲线。
「皮衣教主」黄仁勋可能睡觉都能笑醒。就在新冠疫情给电子消费、零售、制造等行业带来「深度衰退」时，以数据中心为代表的云计算行业却迎来逆势增长。近日，DIGITIMES 报道，在新冠疫情大流行期间，数据中心对高性能计算 HPC、AI 应用需求旺盛，英伟达、AMD 服务器芯片销量正在增加。
实际上，以服务器芯片为代表的英伟达数据中心业务，已经连续多个季度获得快速增长。从 2019 年财年的 25%，增长到 2020 年财年（截至 2020 年 1 月 26 日）的 27.4%，再到 2021 财年第一季度（截至 4 月 26 日）的 37%。数据中心业务对英伟达整体营收的贡献越来越重要，和英伟达「传统」优势领域游戏板块业务旗鼓相当。
而就在一个多月以前的 2020 年 GTC 线上发布会上，英伟达切合时宜地顺应了云市场需求激增这一市场趋势。发布会没有出现传闻中的 Ampere GeForce RTX 3080 游戏显卡，数据中心产品却成为了「绝对主角」，赚足了闪光灯。英伟达推出了第八代 GPU 架构 Ampere 安培，新一代 A100 计算卡，不但在工艺制程上跨越至 7nm，更在多个关键性能参数指标上呈数倍、乃至数十倍增长。
这是英伟达时隔三年，再度向市场扔出的重磅「核弹」，英伟达的目标很明确，就是 AI 训练兼推理芯片、高性能计算 HPC 领域。当然，英伟达占领的也不仅仅是服务器芯片为代表的硬件市场，其最大的「杀手锏」在于软硬一体的生态布局。
「最大的对手是自己」
英伟达 CEO 黄仁勋评价 A100 GPU，「这是英伟达有史以来最好的数据中心 GPU 芯片，几乎是当今半导体的理论极限，它是英伟达数十年以来数据中心经验的结晶。」
的确，A100 GPU 引起了包括亚马逊 AWS、谷歌云、微软 Azure、阿里云、百度云、腾讯云等云巨头，以及戴尔、浪潮、HPE、新华三、思科等系统制造商极大的采购热情。并且，在 A100 GPU 发布之前，就已经投产，开始逐步向云厂商们交付。
用黄仁勋的话来描述就是「前所未有」。
八年以前，黄仁勋绝对想不到，英伟达能够 C 端、B 端通吃，踩准了 AI 时代的每个关键节点，为深度学习提供强大算力，推动图片、语音、自动驾驶、机器人、乃至数据中心的飞速发展。如今，相比于 21 年前刚上市时，英伟达市值已翻了千余倍。
2012 年，ImageNet 大赛上，参赛者因使用英伟达 GPU+CUDA，将深度卷积神经网络 AlexNet 准确率提高 10% 以上，获得冠军，也让英伟达名声大噪。此后，英伟达 GPU 和 CUDA 软件一直主导深度学习市场，几乎所有深度学习开发者离不开英伟达 GPU+CUDA 组合。
包括 2016 年，直接引爆 AI 第三次浪潮的关键事件，AlphaGo 大战李世石，以及亚马逊 AWS、微软，国内的互联网厂商 BAT、美团等 AI 最新进展均有英伟达 GPU 的底层支持。多个第三方研究报告显示，在云端 AI 芯片市场，尤其是云端训练方面，英伟达占据绝对主导地位。
云端、企业级数据中心芯片市场，排名前四位的公有云厂商亚马逊 AWS、微软 Azure、谷歌云、阿里云的上万余个实例类型中，只有很小一部分不基于英伟达 GPU 加速。
不过，这不意味着，英伟达完全没有潜在威胁。英伟达竞争对手大致分为三种：英特尔、AMD 为代表的「老对手」；亚马逊 AWS、谷歌、阿里巴巴、华为为代表的云巨头，以及寒武纪、燧原科技为代表的创业型 AI 芯片公司在内的新对手。
实际上，与其说是新老之争，不如说是 CPU、GPU、ASIC、FPGA 之间的纷争。尽管，英特尔 Xeon CPU 已经安装于全球 99% 的数据中心中，但深度学习、AR/VR、IoT、海量数据处理，推动着数据中心从 CPU 转向 GPU，并成为常态化。
比如，广告位展示、流媒体、电商平台推荐引擎系统、智能语音现在均已采用 GPU 驱动。再如，相同时间周期内芯片性能提高的难易程度不同。2017 年，英伟达推出基于新架构 Volta 的 Tesla V100 芯片，是上一代基于 Pascal 架构的 Tesla P100 训练速度的 12 倍。英伟达在三年之内将 AI 性能提高了 60多倍，而相同时间内，CPU 只能提高一倍。
难怪，黄仁勋自 2017 年以来，多次公开宣布摩尔定律已失效。
在云巨头方面，无论是 AWS Inferentia、谷歌 TPU、阿里巴巴含光 800 均属于 ASIC 芯片，侧重 AI 推理。云巨头自研云端 AI 芯片背后的逻辑有两点，一方面，降低购置芯片的成本，更好服务于自身业务，另一方面，逐步减少对英伟达、英特尔芯片的依赖，提高自己对云生态系统的掌控能力。
一般来说，ASIC 只针对单一场景，速度很快，GPU 的性能以面积和功耗为代价，理论上 ASIC 性能优于 GPU。但 ASIC 研发较慢，有时候赶不上深度学习的发展速度。在价格方面甚至更昂贵，谷歌官网显示，使用 TPU 价格为 8 美元/时，英伟达芯片则为 2.48 美元/小时。
「AI 训练芯片的研发难度更高，目前还是 GPU 占据了很大的优势。主要是英伟达围绕自己的 GPU 已经构建了丰富的软件生态。其他 ASIC 或 FPGA 在硬件指标上可能占据优势，但在生态上比英伟达还落后很多，这也是为什么英伟达一家独大的原因。」芯谋研究徐可告诉极客公园。
芯片行业的「苹果公司」
黄仁勋曾说过，英伟达是一家 AI 公司，更强调英伟达是一家软件公司，和苹果类似，通过售卖硬件盈利的软件公司。
2006 年，英伟达面向开发者推出 CUDA 通用并行计算平台，通过 CUDA 平台，开发者可以使用 C 或 C++语言编程，来加速计算应用程序，极大地简化了软件开发过程。英伟达投入大量资金构筑 CUDA 生态，通过开设课程、培训，吸引开发者，渗透至各个关键行业用户，这是竞争对手 AMD 所不具备的能力。
近三四年，英伟达开发者数量增长迅猛，仅 2019 年一年，CUDA 平台的下载量就超过了 500 万次。不仅如此，在 CUDA 平台之上，英伟达还提供 CUDA-X 软件加速库集合，其中，CUDA-X AI 囊括了加速深度学习的 cuDNN、加速机器学习算法的 cuML、优化训练模型以进行推理的 TensorRT 等 15 个库，此外，英伟达还推出 RAPIDS 开源软件平台，加速企业数据分析、机器学习。
去年年底，黄仁勋在接受 GamesBeat 采访时谈到，英伟达基于 GPU 芯片构建出了非常复杂的软件堆栈，而软件堆栈是竞争对手不具备的「赛道」。
可见，CUDA 平台在内的软件能力，已经成为英伟达的「护城河」。比如，2017 年，英伟达推出面向 AI 训练和高性能计算的 Tesla V100 芯片后，长达两年多的时间里，没有新的后续产品推出。软件成为提高 AI 性能的关键，ResNet-50 神经网络在软件的帮助下，AI 训练能力提高了 100%。
在 GPU 硬件方面，英伟达也在巩固、增强固有优势。2019 年，英伟达收购 Mellanox，弥补了英伟达在数据中心低延迟互连及网络方面的欠缺，显著增强 NVLink（GPU 与 GPU 互联）和 NVSwitch（整合多个 NVLink）互联的速度与可扩展性。
2016 年，英伟达面向 AI 创业公司，推出初创加速计划，帮助 AI 创业公司加速孵化、商业落地。巨头竞争的本质是生态上的竞争。
「生态和软件非常关键。AI 芯片只是底层的工具，AI 开发者对 AI 芯片相关生态和软件的选择，决定了芯片的前途。」徐可说。
在经历游戏显卡业务想象力登顶，比特币挖矿机行业「过山车」式的起伏后，英伟达正凭借数据中心业务进阶 B 端。现在看来，英伟达押宝数据中心前景与钱景巨大，数据中心业务与英伟达强大的软件、生态能力产生的化学反应，正驱动英伟达在芯片市场讲出一个新的增长故事。
转载请联系极客君微信 geekparker
